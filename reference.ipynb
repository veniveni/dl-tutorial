{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_ERC-KKA-FC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data"
      ]
    },
    {
      "metadata": {
        "id": "mA0joW1K68Qw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cVIjYF07gFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eDMn_dKDz7nd",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 5646
        },
        "outputId": "9cdd064d-9b62-4d29-a01f-28ce18b8b51f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "fnames = files.upload()\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "fnames_keys = list(fnames.keys())\n",
        "fnames_keys.sort()\n",
        "for fname in fnames_keys:\n",
        "    tmp = open('temp.bmp','wb')\n",
        "    tmp.write(fnames[fname])\n",
        "    tmp.close()\n",
        "    x.append(plt.imread('temp.bmp'))\n",
        "    y.append(int(fname[0]))\n",
        "X = np.array(x)\n",
        "Y = np.array(y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b6127f6-5a1b-48af-8620-7d6588501e6f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0b6127f6-5a1b-48af-8620-7d6588501e6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 0_0D9Z.bmp to 0_0D9Z (1).bmp\n",
            "Saving 0_0IRS.bmp to 0_0IRS (1).bmp\n",
            "Saving 0_0UAq.bmp to 0_0UAq (1).bmp\n",
            "Saving 0_1vIo.bmp to 0_1vIo (1).bmp\n",
            "Saving 0_2bkj.bmp to 0_2bkj (1).bmp\n",
            "Saving 0_2CNh.bmp to 0_2CNh (1).bmp\n",
            "Saving 0_3OLY.bmp to 0_3OLY (1).bmp\n",
            "Saving 0_3SXv.bmp to 0_3SXv (1).bmp\n",
            "Saving 0_3UJV.bmp to 0_3UJV (1).bmp\n",
            "Saving 0_3Y01.bmp to 0_3Y01 (1).bmp\n",
            "Saving 0_3ZNf.bmp to 0_3ZNf (1).bmp\n",
            "Saving 0_4E6T.bmp to 0_4E6T (1).bmp\n",
            "Saving 0_4Ejn.bmp to 0_4Ejn (1).bmp\n",
            "Saving 0_4PvO.bmp to 0_4PvO (1).bmp\n",
            "Saving 0_6tMj.bmp to 0_6tMj (1).bmp\n",
            "Saving 0_6ZLz.bmp to 0_6ZLz (1).bmp\n",
            "Saving 0_8g0N.bmp to 0_8g0N (1).bmp\n",
            "Saving 0_8qtI.bmp to 0_8qtI (1).bmp\n",
            "Saving 0_8st7.bmp to 0_8st7 (1).bmp\n",
            "Saving 0_9fq1.bmp to 0_9fq1 (1).bmp\n",
            "Saving 0_9thf.bmp to 0_9thf (1).bmp\n",
            "Saving 0_28lo.bmp to 0_28lo (1).bmp\n",
            "Saving 0_35k5.bmp to 0_35k5 (1).bmp\n",
            "Saving 0_39vi.bmp to 0_39vi (1).bmp\n",
            "Saving 0_70kK.bmp to 0_70kK (1).bmp\n",
            "Saving 0_655p.bmp to 0_655p (1).bmp\n",
            "Saving 0_a6A9.bmp to 0_a6A9 (1).bmp\n",
            "Saving 0_Ab4t.bmp to 0_Ab4t (1).bmp\n",
            "Saving 0_Abz4.bmp to 0_Abz4 (1).bmp\n",
            "Saving 0_asNe.bmp to 0_asNe (1).bmp\n",
            "Saving 0_beBe.bmp to 0_beBe (1).bmp\n",
            "Saving 0_BIi4.bmp to 0_BIi4 (1).bmp\n",
            "Saving 0_bnIg.bmp to 0_bnIg (1).bmp\n",
            "Saving 0_bTaO.bmp to 0_bTaO (1).bmp\n",
            "Saving 0_BxK4.bmp to 0_BxK4 (1).bmp\n",
            "Saving 0_bZge.bmp to 0_bZge (1).bmp\n",
            "Saving 0_c2rs.bmp to 0_c2rs (1).bmp\n",
            "Saving 0_cEvF.bmp to 0_cEvF (1).bmp\n",
            "Saving 0_Cgfg.bmp to 0_Cgfg (1).bmp\n",
            "Saving 0_CpDe.bmp to 0_CpDe (1).bmp\n",
            "Saving 0_CQsH.bmp to 0_CQsH (1).bmp\n",
            "Saving 0_crcE.bmp to 0_crcE (1).bmp\n",
            "Saving 0_Ctf4.bmp to 0_Ctf4 (1).bmp\n",
            "Saving 0_CuOU.bmp to 0_CuOU (1).bmp\n",
            "Saving 0_Cyeo.bmp to 0_Cyeo (1).bmp\n",
            "Saving 0_d1Mu.bmp to 0_d1Mu (1).bmp\n",
            "Saving 0_D2eK.bmp to 0_D2eK (1).bmp\n",
            "Saving 0_d4DH.bmp to 0_d4DH (1).bmp\n",
            "Saving 0_d7p8.bmp to 0_d7p8 (1).bmp\n",
            "Saving 0_D19O.bmp to 0_D19O (1).bmp\n",
            "Saving 0_dBBF.bmp to 0_dBBF (1).bmp\n",
            "Saving 0_dbrv.bmp to 0_dbrv (1).bmp\n",
            "Saving 0_dNUE.bmp to 0_dNUE (1).bmp\n",
            "Saving 0_dNX7.bmp to 0_dNX7 (1).bmp\n",
            "Saving 0_DPYq.bmp to 0_DPYq (1).bmp\n",
            "Saving 0_dQIY.bmp to 0_dQIY (1).bmp\n",
            "Saving 0_DtdH.bmp to 0_DtdH (1).bmp\n",
            "Saving 0_dxRB.bmp to 0_dxRB (1).bmp\n",
            "Saving 0_e6y0.bmp to 0_e6y0 (1).bmp\n",
            "Saving 0_eC8z.bmp to 0_eC8z (1).bmp\n",
            "Saving 0_Ekqz.bmp to 0_Ekqz (1).bmp\n",
            "Saving 0_F49I.bmp to 0_F49I (1).bmp\n",
            "Saving 0_FAzN.bmp to 0_FAzN (1).bmp\n",
            "Saving 0_fO70.bmp to 0_fO70 (1).bmp\n",
            "Saving 0_fuAT.bmp to 0_fuAT (1).bmp\n",
            "Saving 0_Fuoi.bmp to 0_Fuoi (1).bmp\n",
            "Saving 0_g7yq.bmp to 0_g7yq (1).bmp\n",
            "Saving 0_GDWA.bmp to 0_GDWA (1).bmp\n",
            "Saving 0_GM57.bmp to 0_GM57 (1).bmp\n",
            "Saving 0_GQuS.bmp to 0_GQuS (1).bmp\n",
            "Saving 0_gsbU.bmp to 0_gsbU (1).bmp\n",
            "Saving 0_hDaE.bmp to 0_hDaE (1).bmp\n",
            "Saving 0_hf0c.bmp to 0_hf0c (1).bmp\n",
            "Saving 0_HFla.bmp to 0_HFla (1).bmp\n",
            "Saving 0_HGJ1.bmp to 0_HGJ1 (1).bmp\n",
            "Saving 0_Hort.bmp to 0_Hort (1).bmp\n",
            "Saving 0_Hrts.bmp to 0_Hrts (1).bmp\n",
            "Saving 0_Hts4.bmp to 0_Hts4 (1).bmp\n",
            "Saving 0_hUp9.bmp to 0_hUp9 (1).bmp\n",
            "Saving 0_HZJT.bmp to 0_HZJT (1).bmp\n",
            "Saving 0_i0we.bmp to 0_i0we (1).bmp\n",
            "Saving 0_I3Q1.bmp to 0_I3Q1 (1).bmp\n",
            "Saving 0_IbIi.bmp to 0_IbIi (1).bmp\n",
            "Saving 0_Igwg.bmp to 0_Igwg (1).bmp\n",
            "Saving 0_Iu3h.bmp to 0_Iu3h (1).bmp\n",
            "Saving 0_iuMc.bmp to 0_iuMc (1).bmp\n",
            "Saving 0_iZWb.bmp to 0_iZWb (1).bmp\n",
            "Saving 0_j4Su.bmp to 0_j4Su (1).bmp\n",
            "Saving 0_jcoh.bmp to 0_jcoh (1).bmp\n",
            "Saving 0_jiKO.bmp to 0_jiKO (1).bmp\n",
            "Saving 0_jsj3.bmp to 0_jsj3 (1).bmp\n",
            "Saving 0_JzsQ.bmp to 0_JzsQ (1).bmp\n",
            "Saving 0_kh1b.bmp to 0_kh1b (1).bmp\n",
            "Saving 0_KMSr.bmp to 0_KMSr (1).bmp\n",
            "Saving 0_KsCl.bmp to 0_KsCl (1).bmp\n",
            "Saving 0_Kwwt.bmp to 0_Kwwt (1).bmp\n",
            "Saving 0_KyQx.bmp to 0_KyQx (1).bmp\n",
            "Saving 0_kzHV.bmp to 0_kzHV (1).bmp\n",
            "Saving 0_l17l.bmp to 0_l17l (1).bmp\n",
            "Saving 0_lBMT.bmp to 0_lBMT (1).bmp\n",
            "Saving 0_liVr.bmp to 0_liVr (1).bmp\n",
            "Saving 0_lPCx.bmp to 0_lPCx (1).bmp\n",
            "Saving 0_lSGx.bmp to 0_lSGx (1).bmp\n",
            "Saving 0_lSJs.bmp to 0_lSJs (1).bmp\n",
            "Saving 0_M6kg.bmp to 0_M6kg (1).bmp\n",
            "Saving 0_MEcH.bmp to 0_MEcH (1).bmp\n",
            "Saving 0_mm8t.bmp to 0_mm8t (1).bmp\n",
            "Saving 0_mr4m.bmp to 0_mr4m (1).bmp\n",
            "Saving 0_MtI6.bmp to 0_MtI6 (1).bmp\n",
            "Saving 0_Neyk.bmp to 0_Neyk (1).bmp\n",
            "Saving 0_NJjq.bmp to 0_NJjq (1).bmp\n",
            "Saving 0_NW94.bmp to 0_NW94 (1).bmp\n",
            "Saving 0_nWdo.bmp to 0_nWdo (1).bmp\n",
            "Saving 0_o5O9.bmp to 0_o5O9 (1).bmp\n",
            "Saving 0_o7e4.bmp to 0_o7e4 (1).bmp\n",
            "Saving 0_oDg8.bmp to 0_oDg8 (1).bmp\n",
            "Saving 0_ODRf.bmp to 0_ODRf (1).bmp\n",
            "Saving 0_ohd4.bmp to 0_ohd4 (1).bmp\n",
            "Saving 0_OpxF.bmp to 0_OpxF (1).bmp\n",
            "Saving 0_OTLK.bmp to 0_OTLK (1).bmp\n",
            "Saving 0_p6Q4.bmp to 0_p6Q4 (1).bmp\n",
            "Saving 0_PB02.bmp to 0_PB02 (1).bmp\n",
            "Saving 0_pFcd.bmp to 0_pFcd (1).bmp\n",
            "Saving 0_PN3L.bmp to 0_PN3L (1).bmp\n",
            "Saving 0_pRHe.bmp to 0_pRHe (1).bmp\n",
            "Saving 0_Py57.bmp to 0_Py57 (1).bmp\n",
            "Saving 0_qF8u.bmp to 0_qF8u (1).bmp\n",
            "Saving 0_qGFE.bmp to 0_qGFE (1).bmp\n",
            "Saving 0_QOWe.bmp to 0_QOWe (1).bmp\n",
            "Saving 0_QrMa.bmp to 0_QrMa (1).bmp\n",
            "Saving 0_qYBT.bmp to 0_qYBT (1).bmp\n",
            "Saving 0_qzTh.bmp to 0_qzTh (1).bmp\n",
            "Saving 0_r08P.bmp to 0_r08P (1).bmp\n",
            "Saving 0_RBHk.bmp to 0_RBHk (1).bmp\n",
            "Saving 0_rdsL.bmp to 0_rdsL (1).bmp\n",
            "Saving 0_recz.bmp to 0_recz (1).bmp\n",
            "Saving 0_RjrB.bmp to 0_RjrB (1).bmp\n",
            "Saving 0_Rkhi.bmp to 0_Rkhi (1).bmp\n",
            "Saving 0_Rn8Y.bmp to 0_Rn8Y (1).bmp\n",
            "Saving 0_sdU0.bmp to 0_sdU0 (1).bmp\n",
            "Saving 0_se88.bmp to 0_se88 (1).bmp\n",
            "Saving 0_Sgqb.bmp to 0_Sgqb (1).bmp\n",
            "Saving 0_SjfP.bmp to 0_SjfP (1).bmp\n",
            "Saving 0_SkUQ.bmp to 0_SkUQ (1).bmp\n",
            "Saving 0_sNmZ.bmp to 0_sNmZ (1).bmp\n",
            "Saving 0_SpKa.bmp to 0_SpKa (1).bmp\n",
            "Saving 0_SS1a.bmp to 0_SS1a (1).bmp\n",
            "Saving 0_sT8U.bmp to 0_sT8U (1).bmp\n",
            "Saving 0_TeK4.bmp to 0_TeK4 (1).bmp\n",
            "Saving 0_Tj9n.bmp to 0_Tj9n (1).bmp\n",
            "Saving 0_tjj6.bmp to 0_tjj6 (1).bmp\n",
            "Saving 0_TjxA.bmp to 0_TjxA (1).bmp\n",
            "Saving 0_TlJA.bmp to 0_TlJA (1).bmp\n",
            "Saving 0_TQsX.bmp to 0_TQsX (1).bmp\n",
            "Saving 0_u0rI.bmp to 0_u0rI (1).bmp\n",
            "Saving 0_U9F8.bmp to 0_U9F8 (1).bmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "67SuaTtC1xQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "def split_train_test(X, Y, train_frac = 0.85):\n",
        "    n_samples_per_letter = int(X.shape[0]/3)\n",
        "    split = int(train_frac*n_samples_per_letter)\n",
        "    r = list(range(n_samples_per_letter))\n",
        "    random.shuffle(r)\n",
        "    train_indices = r[:split]\n",
        "    train_indices += list(map(lambda x: x+n_samples_per_letter, train_indices)) + list(map(lambda x: x + 2*n_samples_per_letter, train_indices))\n",
        "    test_indices = r[split:]\n",
        "    test_indices += list(map(lambda x: x+n_samples_per_letter, test_indices)) + list(map(lambda x: x + 2*n_samples_per_letter, test_indices))\n",
        "    X_train = X[np.array(train_indices)]\n",
        "    Y_train = Y[np.array(train_indices)]\n",
        "    X_test = X[np.array(test_indices)]\n",
        "    Y_test = Y[np.array(test_indices)]\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n",
        "(X_train, Y_train), (X_test, Y_test) = split_train_test(X,Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_6582N3-pZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Single Layer Model"
      ]
    },
    {
      "metadata": {
        "id": "l2Mt2WS4xVQN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "knH0rrEm_ODW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Flatten and normalize"
      ]
    },
    {
      "metadata": {
        "id": "crDGdDyH-C1A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r94WbWQc_L6N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]\n",
        "X_train = x_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = x_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qEzxRPCc_W0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52034016-df56-4b9d-b9a3-aae72ca0c936"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape , X_test.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((459, 19683), (81, 19683))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "Bs2oLVn6_jra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One-hot for labels"
      ]
    },
    {
      "metadata": {
        "id": "uPdhm3GeBzIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g3qz76UFB063",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f27c2af5-ddca-4b6c-ef4f-ef4028f18c14"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(459, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "aklj7Uv2CAUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The model"
      ]
    },
    {
      "metadata": {
        "id": "I_IjB8aZCCLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "89635e38-fb0f-4b19-f49a-f1da3de79b3d"
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 19683)             387440172 \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 59052     \n",
            "=================================================================\n",
            "Total params: 387,499,224\n",
            "Trainable params: 387,499,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PbstoDVS4dRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "5d332a6b-0f2a-45fa-89d1-0b43d949b3d8"
      },
      "cell_type": "code",
      "source": [
        "fnames"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3d3a0863b373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'fnames' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "v3eaelFdCijj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "01063390-bcf2-401d-f8bd-7bcf5b00e6cc"
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Show training progress\n",
        "plt.plot(history.history['acc'], 'b--')\n",
        "plt.plot(history.history['val_acc'], 'r--')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'], 'b-')\n",
        "plt.plot(history.history['val_loss'], 'r-')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 459 samples, validate on 81 samples\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "otrcMpD1HevI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ]
    },
    {
      "metadata": {
        "id": "5032FWXnHgxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_idx = 157\n",
        "\n",
        "image = X_test[test_idx]\n",
        "image = image.reshape(28, 28)\n",
        "image = image * 255\n",
        "image = image.astype(np.uint8)\n",
        "plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "\n",
        "label = y_test[test_idx]\n",
        "print(f\"label: {label}\")\n",
        "\n",
        "prediction = model.predict(X_test[test_idx:test_idx+1])\n",
        "print(f\"prediction: {prediction}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJZBW5PmbZtB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Overfitting"
      ]
    },
    {
      "metadata": {
        "id": "nWGLAP1Iboyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgvGtsWMb0r6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the model on 1/100 of the data but with 100 times the epochs"
      ]
    },
    {
      "metadata": {
        "id": "dj1qK79dbusm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train[:600], y_train[:600], validation_data=(X_test[:100], y_test[:100]), epochs=100, batch_size=200, verbose=0)\n",
        "\n",
        "# Show training progress\n",
        "plt.plot(history.history['acc'], 'b--')\n",
        "plt.plot(history.history['val_acc'], 'r--')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'], 'b-')\n",
        "plt.plot(history.history['val_loss'], 'r-')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0HzLycwG3iW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ]
    },
    {
      "metadata": {
        "id": "zehhDA3yG6YR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ES6vb2J4HEMD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "R2Its1mbHIuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGRvWrfpHLp3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1UYwGwfYHfLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "fGASroKBHgy6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3t44b1BArL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Show training progress\n",
        "plt.plot(history.history['acc'], 'b--')\n",
        "plt.plot(history.history['val_acc'], 'r--')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'], 'b-')\n",
        "plt.plot(history.history['val_loss'], 'r-')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSRKIXNYDfh0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Larger CNN"
      ]
    },
    {
      "metadata": {
        "id": "zz6Dkzm0Dkt0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HnfOTbOEDzRw"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Udu1fj4aDzRy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DjKpA4f0DzR1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oHQCCoe0DzR5"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IOgKPvHDzR6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FaA8FIL0DzR8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Show training progress\n",
        "plt.plot(history.history['acc'], 'b--')\n",
        "plt.plot(history.history['val_acc'], 'r--')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'], 'b-')\n",
        "plt.plot(history.history['val_loss'], 'r-')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7GabxZEoXGzr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Finetuning "
      ]
    },
    {
      "metadata": {
        "id": "m_MXL5QKe1lg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "wFp9TNNJYZE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# flip\n",
        "X_train = X_train[:, ::-1, :]\n",
        "X_test = X_test[:, ::-1, :]\n",
        "\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6eBTdqgQfy6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HI9MtAhgnkP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "HEGSNx8GXJmX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# update model\n",
        "model.pop()\n",
        "model.pop()\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# freeze layers\n",
        "for layer in model.layers[:-2]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QajoWY7gWcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train[:600], y_train[:600], validation_data=(X_test, y_test), epochs=100, batch_size=200, verbose=0)\n",
        "\n",
        "# Show training progress\n",
        "plt.plot(history.history['acc'], 'b--')\n",
        "plt.plot(history.history['val_acc'], 'r--')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'], 'b-')\n",
        "plt.plot(history.history['val_loss'], 'r-')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}